# CycleGAN
CycleGAN - Horse2zebra Dataset


# **Generative Adversarial Networks**
GAN modeline üretmek istediğiniz veriden yeterli sayıda örnek verirseniz yine aynı veri tipinde yeni örnekler ürettirebilirsiniz. Sisteme binlerce kuş fotoğrafı verirseniz sistem, bir kuşun nasıl görünmesi gerektiğini öğrenecek ve yeni kuş fotoğrafları üretecektir. GAN’lerde birbiriyle çekişme halinde bulunan 2 farklı yapay sinir ağı bulunmaktadır. Bunlar Üretici (Generator) ve Ayırt Edici (Discriminator) ağ olarak adlandırılır. Üretici ağ, gerçeğe benzeyen yeni veriler (resimler, sesler, modeller vb.) üretirken Ayırt Edici ağ da sahte ve gerçek verileri birbirinden ayırt etmeye çalışır. Bu iki sinir ağı birbiriyle çekişirken Ayırt Edici ağ giderek gerçek ve sahte resimleri daha iyi ayırt etmeye başlar. Üretici ağ ise daha gerçekçi sahte resimler üretir. Bu düzeni kalpazan ve polis ikilisine benzetebiliriz. Zaman ilerledikçe polis, kalpazanları bulabilmek için sahte paraları yakalamada daha başarılı olur. Kalpazan ise polisi yenebilmek için daha gerçekçi sahte paralar üretmeye başlar.
Peki bu çekişme esnasında sistemin daha iyi sonuçlar üretmesi nasıl sağlanır? Ayırt edici ağ, kendisine gelen resimlerin gerçek olma olasılıklarını hesaplar ve bunlara 0 ve 1 arasında bir değer verir. Gerçek bir resmin gerçek olma olasılığı 1, sahte bir resminki ise 0 olmalıdır. Ayırt Edici ağ, verdiği olasılık değerleri ile olması gereken değerler arasındaki fark olan kayıp (loss) değeri kullanılarak eğitilir. Örneğin Ayırt Edici ağ gerçek bir resme 0.7 değerini vermişse 1–0.7 = 0.3 hata yapmıştır. Tam tersi olarak sahte bir resme 0.7 değeri vermişse de 0.7–0 = 0.7 hata yapmıştır. Ayırt edici ağın değerleri eğitim sırasında her iterasyonda bu hata değerlerini 0’a indirecek şekilde güncellenir. Üretici ağ ise tam tersi olarak kendi ürettiği sahte resimlerin gerçeğe yakın olmasını yani 1 olarak değerlendirilmesini ister. Eğer kendi ürettiği resmi Ayırt Edici ağ 0.6 olarak değerlendirmişse, Üretici ağ 1–0.6=0.4 hata yapmıştır. Üretici Ağ da her iterasyonda bu hatayı 0’a indirmeyi ister. Bu şekilde eğitim süreci ilerledikçe ayırt edici ağ, gerçek ve sahte resimleri ayırt etme işinde daha başarılı olur. Üretici ağ ise daha gerçekçi sahte resimler üretir. Eğitim süreci bittiğinde elimizde gerçeğinden ayırt edilemeyecek kalitede resimler üreten bir üretici sistem kalır.

# **Horse to a Zebra: CycleGAN**
Adından da anlaşılacağı gibi, projemizin amacı basittir: bir at görüntüsü alan ve onu bir zebra görüntüsüne çeviren bir makine yapmak. İdeal olarak, makinemiz yalnızca atın derisindeki deseni değiştirirken arka plan, atın şekli, görüntüdeki diğer nesneler vb. gibi diğer özellikleri tamamen değiştirmeden bırakır. Bu tür bir göreve, halihazırda çok sayıda makalenin bulunduğu sinir ağı altında oldukça olgun bir araştırma konusu olan Görüntüden Görüntüye Çeviri adı verilir.

Geleneksel olarak, bir Görüntüden Görüntüye Çeviri modelini eğitmek için bir “eşleştirilmiş örneklerden” oluşan bir veri setine ihtiyacımız olacak, yani bir resmi gerçek bir fotoğrafa aktarmak istiyorsak, yüzlerce tabloya ve buna karşılık gelen gerçek- sanat eserlerinin boyandığı hayat fotoğrafları. Ancak karşılaştığımız zorluk şu ki, atlarımız için “eşleştirilmiş zebra görüntüleri” bulmamız imkansız, çünkü böyle şeyler hiç yok. Bu nedenle, dönüşümü gerçekleştirmek için eğitimde bu tür “eşleştirilmiş örnekler” gerektirmeyen cycleGAN adlı bir model kullanıyoruz. Jun-yan Zhu ve UC Berkeley'deki meslektaşları tarafından 2017'de tanıtılan cycleGAN, Görüntüden Görüntüye Çeviri yapmanın yeni bir yolunu sunuyor. Antrenmanda hala bir dizi at görüntüsü ve bir dizi zebra görüntüsü gerektirse de, at ve zebra görüntülerinin artık birbirleriyle doğrudan ilişkili olması gerekmiyor.

Bir attan zebraya cycleGAN modelini eğitmek için iki veri setine ihtiyacımız var: gerçek hayattaki at görüntüleri ve zebra görüntüleri. Projemizde, cycleGAN için resmi Github sayfasından alınan iyi organize edilmiş bir veri seti kullanıyoruz. Veri kümesi, her biri yaklaşık 1.400 at veya zebra fotoğrafına sahip iki eğitim klasörü içerir. Bu fotoğraflar modeli eğitmek için kullanılır. Ayrıca, model performansını değerlendirmek için 10 at fotoğrafı ve 10 zebra fotoğrafı veri kümesinin test klasörlerine kaydedilir.
# **CycleGAN'a Giriş**
Geleneksel bir Görüntüden Görüntüye Çevirisi, iki sinir ağı biriminden oluşan tek bir GAN modeli aracılığıyla gerçekleştirilebilir: biri Jeneratör, diğeri Ayırıcı olarak adlandırılır. Bir cycleGAN modeli için aslında iki GAN modeli tarafından oluşturulmuştur. Neden iki taneye ihtiyacımız olduğunu sormadan önce, önce bu iki GAN'ın bir cycleGAN içinde nasıl yapılandırıldığından bahsedelim.

CycleGAN olarak adlandırılmasının nedeni, birazdan bahsedeceğimiz bir amaç için bir döngü oluşturmak için iki GAN modelini kullanmamızdır. Böyle bir döngüyü yapmak için, iki GAN modelini tamamen aynı işi yapacak, yani görüntüden görüntüye çeviri yapacak şekilde, ancak ters yönlerde yapmamız gerekiyor. Özellikle, GAN A'nın bir at görüntüsünü bir zebra görüntüsüne aktarmasını, GAN B'nin ise bir zebra görüntüsünü bir at görüntüsüne aktarma becerisine sahip olmasını istiyoruz. İki GAN modelinin her biri, bir Koşullu Üretici ve bir PatchGAN Ayırıcı tarafından oluşturulur. Aşağıdaki bölümde üreteç ve ayrımcıların yapılarından bahsedeceğiz. Özetlemek gerekirse, araç kutumuzda iki GAN modelimiz var. Her biri bir üreteç ve bir ayrımcı içerir.

# **Neden iki taneye ihtiyacımız var?**
Daha önce ortaya atılan soruya geri dönelim: Eğer sadece tek yönlü görüntü çevirisi yapıyorsak veya zebradan ata çeviri olmadan attan zebraya yapıyorsak, modelimizde bunlardan biri alabilirken neden iki GAN'a ihtiyacımız var? iş bitti mi? Pekala, bu soruyu cevaplamak için, bir cycleGAN'ın en büyük avantajına geri dönelim: eğitim sürecinde artık çift örnekleri gerektirmeyecek. Ancak, eşleştirilmiş örneklere sahip olmak her zaman kötü bir şey değildir. Eşleştirilmiş örneklerin bir değeri, oluşturulan görüntülere katı kısıtlamalar getirmeleridir, böylece istenen ayarlamalar (örneğin zebra deseni) dışında, oluşturulan görüntülerin geri kalan kısmı kaynak görüntülerden değişmeyecektir. Bu kısıtlamayı, güçlü bir şekilde ilişkili eşleştirilmiş görüntülerle doğal olarak geldiğinden, eşleştirilmiş örneklerimiz olduğunda kesin kabul etsek de, kaynak görüntüler ile hedef görüntüler arasında hiçbir korelasyonun olmadığı eşleştirilmemiş örneklere geçtiğimizde artık durum böyle değil. Bu eşleştirilmemiş örnekler üzerinde tek bir GAN'ı eğitmeye devam edersek sorun yaratabilir, yani eğitimin bir noktasında GAN'ımızın at görüntüleri ile çok az veya hiç korelasyonu olmayan rastgele zebra görüntüleri üretmeye başladığını fark edebiliriz. ile besliyoruz. Bu kesinlikle karşılaşmak istemediğimiz bir durumdur. Bu nedenle, ondan kurtulmak için, cycleGAN'ın dahiyane yaratıcıları, ek bir kayıp işlevi aracılığıyla oluşturulan görüntülere kısıtlamayı geri koyacak olan Döngü Tutarlılığı adlı bir kavram icat etti. Yaratıcıların kendileri, makalelerinde döngü tutarlılığı hakkında mükemmel bir açıklama yaptılar:

“Örneğin, bir cümleyi İngilizce'den Fransızca'ya çevirirsek ve sonra onu tekrar Fransızca'dan İngilizce'ye çevirirsek, orijinal cümleye geri dönmemiz gerektiği anlamında çevirinin "döngü tutarlı" olması gerektiği özelliğinden yararlanırız.”

----Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, 2017.

Fransızca bir cümleyi İngilizceye çevirmek istediğinizi ve işi ne kadar iyi yaptığınızı görmek istediğinizi varsayalım. Çevirinizi değerlendirmenin iyi bir yolu, İngilizce cümleyi tekrar Fransızcaya çevirmek ve ideal olarak, sonucunuz orijinal Fransızca cümle ile tamamen aynı olmalıdır. Aynı mantık buraya da uygulanabilir: oluşturulan görüntüyü girdiyle ilişkilendirmede modelimizin doğru yolda olduğundan emin olmak için, önce GAN A'nın bir at görüntüsü almasına ve onu oluşturulan bir zebra görüntüsüne aktarmasına ve ardından doğrudan beslemesine izin verdik. Doğası gereği bize üretilen bir at görüntüsünü geri verecek olan GAN B. İdeal olarak, nihai olarak oluşturulan at resmi, orijinal at resmiyle tamamen aynı görünmelidir, aynı şekilde yeniden çevrilmiş Fransızca cümle, orijinal Fransızca cümleyle eşleşir. Aralarında önemli bir fark olduğu ortaya çıkarsa, GAN A'nın iyi bir iş yapmamış olabileceğini ve eğitim yoluyla yükseltilmesi gerektiğini biliyoruz. O zaman tek yapmamız gereken, iki at görüntüsü arasındaki farkı bir kayıp fonksiyonuna dönüştürmektir. Bu işleme, GAN A'yı değerlendirmeye odaklanan döngü yapısının bir yarısı olan İleri Döngü denir. Döngünün diğer yarısı, Geri Döngü olarak adlandırılan, muadili ile tam olarak aynı iş akışına sahip olacaktır, ancak ters yönde olacaktır. GAN B'yi değerlendirebilir. İleri ve Geri Döngülerden iki kayıp fonksiyonunu birleştirerek, Döngü Tutarlılık Kaybı adı verilen genel bir kayıp fonksiyonu elde ederiz ve onu cycleGAN modelini güncellemek için kullanacağımız son kayıp fonksiyonunun bir parçası olarak dahil ederiz.

# **Kimlik Kaybı**
Döngü Tutarlılık Kaybı uygulandığında, artık modelimizin yaramazlığı hakkında endişelenmemize gerek yok gibi görünüyor. Bununla birlikte, CycleGAN'ın yaratıcıları, deneylerinden, çıktı zebralarının döngü tutarlılığı kısıtlaması altındaki girdi atlarıyla aynı şekle ve diğer maddelere sahip gibi görünse de, girdiler ve çıktılar arasındaki renk profili tutarlılığının zebralar tarafından çok iyi korunmadığını keşfettiler. modeli. Bu sorunu çözmek için Kimlik Eşleme adı verilen başka bir yapı icat ettiler. Bu yapı yine, birinin GAN A'nın performansına odaklandığı ve diğerinin GAN B'yi değerlendirdiği Döngü Tutarlılığı gibi iki bileşen tarafından inşa edilmiştir. Örneğin, GAN A'yı bir at görüntüsü ile beslemek yerine değerlendirmek için, ona bir zebra görüntüsü vereceğiz. Doğası gereği GAN A, orijinal zebrayı temel alan yeni bir zebra görüntüsü 
ile beslemek yerine değerlendirmek için, ona bir zebra görüntüsü vereceğiz. Doğası gereği GAN A, orijinal zebrayı temel alan yeni bir zebra görüntüsü oluşturacaktır. İdeal olarak, renkler de dahil olmak üzere iki görüntüde bulunan her şey tamamen aynı görünmelidir. Yine, iki görüntü arasındaki farkı bir kayıp işlevine dönüştürüyoruz ve onu diğer bileşenlerden kayıp işleviyle birleştirerek, yine son kayıp işlevinin bir parçası olacak olan bir Kimlik Kaybı işlevi oluşturuyoruz.
